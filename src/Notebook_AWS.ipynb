{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pipeline\n",
    "import filepaths as fp\n",
    "import torch\n",
    "\n",
    "from rnn_model import EncoderRNN, AttnDecoderRNN\n",
    "from rnn_model_train import trainIters\n",
    "from rnn_model_predict import predict_all\n",
    "\n",
    "from pos_model import EncoderPOS, AttnDecoderPOS\n",
    "from pos_model_train import trainIters as trainItersPOS\n",
    "from pos_model_predict import predict_all as predict_allPOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(index_array_pairs, s_vocab_size, t_vocab_size, \n",
    "                max_length):\n",
    "    \n",
    "    # create Encoder/Decoder models \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder = EncoderRNN(s_vocab_size, hidden_size).to(device)\n",
    "    attn_decoder = AttnDecoderRNN(hidden_size, t_vocab_size, max_length, dropout_p).to(device)\n",
    "\n",
    "    # train models and return losses to plot\n",
    "    plot_losses = trainIters(\n",
    "        index_array_pairs, encoder, attn_decoder, n_epochs, max_length, \n",
    "        print_every, plot_every = plot_every, \n",
    "        learning_rate = learning_rate, max_hours = max_hours,\n",
    "        clip = clip)\n",
    "    \n",
    "    # return trained models and info to plot the losses\n",
    "    return encoder, attn_decoder, plot_losses, plot_every\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TOY DATA: to test if every thing is working\n",
    "\n",
    "hidden_size = 256 \n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "max_hours = 9\n",
    "clip = 10\n",
    "plot_every = 15\n",
    "MAX_LENGTH = 24\n",
    "print_every = 60\n",
    "\n",
    "(encoder, attn_decoder, slang, tlang, plot_losses, max_bpe_length) = pipeline.run(\n",
    "    fp.spath_toy, fp.tpath_toy, \n",
    "    fp.spath_toy, fp.tpath_toy, \n",
    "    train_model, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = False, \n",
    "    use_bpe = True, num_operations = 80, vocab_threshold = 1,\n",
    "    padding = False, model_name = 'rnn_toy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RNN: TRAIN and Validation DATA using BPE\n",
    "\n",
    "hidden_size = 256 \n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_epochs = 25\n",
    "max_hours = 8\n",
    "clip = 8\n",
    "use_bpe = True\n",
    "replace_unknown_words = True\n",
    "padding = False\n",
    "MAX_LENGTH = 25\n",
    "plot_every = 200 \n",
    "print_every = 28319 # every epoch\n",
    "\n",
    "(encoder, attn_decoder, slang, tlang, plot_losses, max_bpe_length) = pipeline.run(\n",
    "    fp.spath_train, fp.tpath_train, \n",
    "    fp.spath_test, fp.tpath_test, \n",
    "    train_model, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = True, \n",
    "    use_bpe = True, num_operations = 400, vocab_threshold = 5, \n",
    "    padding = False, model_name = 'rnn_bpe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model_pos(index_array_pairs, s_vocab_size, t_vocab_size, max_length):\n",
    "    \n",
    "    # create Encoder/Decoder models \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder = EncoderPOS(s_vocab_size, max_length, hidden_size).to(device)\n",
    "    attn_decoder = AttnDecoderPOS(hidden_size, t_vocab_size, max_length, dropout_p).to(device)\n",
    "\n",
    "    # train models and return losses to plot\n",
    "    plot_losses = trainItersPOS(\n",
    "        index_array_pairs, encoder, attn_decoder, n_epochs, max_length, \n",
    "        print_every, plot_every = plot_every, \n",
    "        learning_rate = learning_rate, max_hours = max_hours, clip=clip)\n",
    "    \n",
    "    # return trained models and info to plot the losses\n",
    "    return encoder, attn_decoder, plot_losses, plot_every\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TOY DATA\n",
    "hidden_size = 256 \n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "# n_iters = 10\n",
    "n_epochs = 30\n",
    "max_hours = 9\n",
    "clip = 10\n",
    "\n",
    "MAX_LENGTH = 24\n",
    "encoder, attn_decoder, slang, tlang, plot_losses, max_bpe_length = pipeline.run(\n",
    "    fp.spath_toy, fp.tpath_toy, \n",
    "    fp.spath_toy, fp.tpath_toy, \n",
    "    train_model_pos, predict_allPOS, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = False, \n",
    "    use_bpe = False, num_operations = 80, vocab_threshold = 1,\n",
    "    padding = False, model_name = 'pos_toy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TRAIN and TEST DATA WITHOUT BPE\n",
    "# verplaats directory van je modelsss na runnen \n",
    "hidden_size = 256\n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_epochs = 25\n",
    "max_hours = 8\n",
    "clip = 8\n",
    "use_bpe = False\n",
    "replace_unknown_words = True\n",
    "padding = True\n",
    "MAX_LENGTH = 25\n",
    "plot_every = 200\n",
    "print_every = 28319 # every epoch\n",
    "\n",
    "encoder, attn_decoder, slang, tlang, plot_losses, max_bpe_length = pipeline.run(\n",
    "    fp.spath_train, fp.tpath_train, \n",
    "    fp.spath_test, fp.tpath_test, \n",
    "    train_model, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = True, \n",
    "    use_bpe = False, num_operations = 100, vocab_threshold = 1, \n",
    "    padding = False, model_name = 'pos_no_bpe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TRAIN and TEST DATA WITHOUT BPE\n",
    "# verplaats directory van je modelsss na runnen \n",
    "hidden_size = 256\n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_epochs = 25\n",
    "max_hours = 8\n",
    "clip = 8\n",
    "use_bpe = False\n",
    "replace_unknown_words = True\n",
    "padding = True\n",
    "MAX_LENGTH = 25\n",
    "plot_every = 200\n",
    "print_every = 28319 # every epoch\n",
    "\n",
    "encoder, attn_decoder, slang, tlang, plot_losses, max_bpe_length = pipeline.run(\n",
    "    fp.spath_train, fp.tpath_train, \n",
    "    fp.spath_test, fp.tpath_test, \n",
    "    train_model, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = True, \n",
    "    use_bpe = True, num_operations = 400, vocab_threshold = 5, \n",
    "    padding = False, model_name = 'pos_bpe')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
