{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from rnn_model import EncoderRNN, AttnDecoderRNN\n",
    "from rnn_model_train import trainIters\n",
    "\n",
    "import data_preparation as dp\n",
    "import filepaths as fp\n",
    "from rnn_model_predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 256 #256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(slang, tlang, tensor_pairs) = dp.prepare_training_data(\n",
    "    fp.spath_toy, fp.tpath_toy, False)\n",
    "\n",
    "max_length = 0\n",
    "for tp in tensor_pairs:\n",
    "    max_length = max(len(tp[0]), len(tp[1]), max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(slang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, tlang.n_words, max_length, dropout_p=0.1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (- 0m 24s) (50 10%) 0.4908\n",
      "0m 5s (- 0m 20s) (100 20%) 0.5627\n",
      "0m 7s (- 0m 16s) (150 30%) 0.4526\n",
      "0m 9s (- 0m 14s) (200 40%) 0.2277\n",
      "0m 11s (- 0m 11s) (250 50%) 0.1675\n",
      "0m 13s (- 0m 9s) (300 60%) 0.1092\n",
      "0m 15s (- 0m 6s) (350 70%) 0.0756\n",
      "0m 18s (- 0m 4s) (400 80%) 0.0793\n",
      "0m 20s (- 0m 2s) (450 90%) 0.0612\n",
      "0m 22s (- 0m 0s) (500 100%) 0.0612\n"
     ]
    }
   ],
   "source": [
    "trainIters(\n",
    "    tensor_pairs, encoder1, attn_decoder1,  \n",
    "    1500, max_length, print_every=150, plot_every=15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man and a woman walking in the city .\n",
      "\n",
      "a waterfall in a forest with many trees .\n",
      "\n",
      "a bee hovering over purple and orange flowers .\n",
      "\n",
      "a calm lake surrounded by trees and rocks .\n",
      "\n",
      "two people on a football field one on the ground .\n",
      "\n",
      "a young man performs an aerial stunt on a skateboard .\n",
      "\n",
      "two dogs running along the beach .\n",
      "\n",
      "a dog is running beside a body of water .\n",
      "\n",
      "a cyclist is wearing a helmet .\n",
      "\n",
      "a man wearing a black hat is shooting a rifle outside .\n",
      "\n",
      "a small child outside with autumn leaves blowing around her face .\n",
      "\n",
      "a bright red boat on perfectly calm blue water .\n",
      "\n",
      "a wooden walkway leading up a grassy slope under a blue sky .\n",
      "\n",
      "a bike race is taking place with spectators watching .\n",
      "\n",
      "a four wheeled wooden cart parked on a a wooden platform .\n",
      "\n",
      "customers are standing outside of a convenience store .\n",
      "\n",
      "a woman poses on a rocky beach as her friend takes a photo .\n",
      "\n",
      "a man and two girls playing on the shore of the beach .\n",
      "\n",
      "a little girl playing with her toys in the sand .\n",
      "\n",
      "a man in pinstripe pants is performing a concert .\n",
      "\n",
      "two people laying on the sidewalk in front of a wall of graffiti .\n",
      "\n",
      "a body of water with sunshine breaking through clouds .\n",
      "\n",
      "a plane with a banner flying above a beach with people on the sand and in the water .\n",
      "\n",
      "a white small jet taking off with water to the side .\n",
      "\n",
      "a young girl poses fiercely while using exercise equipment .\n",
      "\n",
      "privately owned poster and restaurant poster .\n",
      "\n",
      "pines , and some background mountains with snow .\n",
      "\n",
      "a women bending over with a kissing expression at a black primate creature while standing on a harwood floor .\n"
     ]
    }
   ],
   "source": [
    "for tp in tensor_pairs:\n",
    "    s_tensor = tp[0]\n",
    "#     print(s_tensor)\n",
    "    t_indices, a = predict(encoder1, attn_decoder1, s_tensor, max_length)\n",
    "    print(dp.sentenceFromIndexes(tlang, t_indices))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(slang, tlang, index_array_pairs) = dp.prepare_training_data(\n",
    "    fp.spath_toy, fp.tpath_toy, False)\n",
    "\n",
    "max_length = 0\n",
    "for tp in index_array_pairs:\n",
    "    max_length = max(len(tp[0]), len(tp[1]), max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = EncoderRNN(slang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, tlang.n_words, max_length, dropout_p=0.1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_pairs = [\n",
    "    (\n",
    "        torch.tensor(s_indices, dtype=torch.long, device=device).view(-1, 1),\n",
    "        torch.tensor(t_indices, dtype=torch.long, device=device).view(-1, 1),\n",
    "    )\n",
    "    for (s_indices, t_indices) in index_array_pairs\n",
    "]\n",
    "\n",
    "trainIters(\n",
    "    tensor_pairs, encoder1, attn_decoder1,  \n",
    "    500, max_length, print_every=50, plot_every=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tp in tensor_pairs:\n",
    "    s_tensor = tp[0]\n",
    "    print(s_tensor)\n",
    "    t_indices, a = predict(encoder1, attn_decoder1, s_tensor, max_length)\n",
    "    print(dp.sentenceFromIndexes(tlang, t_indices))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIters(\n",
    "    index_array_pairs, encoder1, attn_decoder1,  \n",
    "    500, max_length, print_every=50, plot_every=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: input/output to train and evaluate \n",
    "# should be arrays of indices instead of tensors.\n",
    "# then torch can be moved out of data prep\n",
    "# and input/output types are consistent\n",
    "s = 'un homme en pantalon ray√© fait un concert .'\n",
    "t = 'a man in pinstripe pants is performing a concert .'\n",
    "\n",
    "s_tensor = dp.tensorFromSentence(slang, s)\n",
    "i, a = predict(encoder1, attn_decoder1, s_tensor, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(s_tensor.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[[2], [3], [9], [122], [123], [42], [2], [124], [11], [1]]\n",
    "slang.index2word[11]\n",
    "slang.index2word[167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slang.index2word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceFromIndexes(lang, indices):\n",
    "    words = [lang.index2word[index] for index in indices]\n",
    "    return ' '.join(words[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceFromIndexes(tlang, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tp in tensor_pairs:\n",
    "    s_tensor = tp[0]\n",
    "    print(s_tensor)\n",
    "    t_indices, a = predict(encoder1, attn_decoder1, s_tensor, max_length)\n",
    "    print(dp.sentenceFromIndexes(tlang, t_indices))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = _indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mj():\n",
    "    tensor_pairs = [\n",
    "        (\n",
    "            torch.tensor(s_indices, dtype=torch.long, device=device).view(-1, 1),\n",
    "            torch.tensor(t_indices, dtype=torch.long, device=device).view(-1, 1),\n",
    "        )\n",
    "        for (s_indices, t_indices) in index_array_pairs\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_array_pairs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_pairs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
