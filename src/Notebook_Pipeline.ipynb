{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline\n",
    "import filepaths as fp\n",
    "\n",
    "import torch\n",
    "from rnn_model import EncoderRNN, AttnDecoderRNN\n",
    "from rnn_model_train import trainIters\n",
    "from rnn_model_predict import predict_all, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(index_array_pairs, s_vocab_size, t_vocab_size, \n",
    "                max_length):\n",
    "    \n",
    "    # create Encoder/Decoder models \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    encoder = EncoderRNN(s_vocab_size, hidden_size).to(device)\n",
    "    attn_decoder = AttnDecoderRNN(hidden_size, t_vocab_size, max_length, dropout_p).to(device)\n",
    "\n",
    "    # train models and return losses to plot\n",
    "    plot_every = n_epochs * len(index_array_pairs)/200.\n",
    "    print_every=n_epochs * len(index_array_pairs)/25.\n",
    "    plot_losses = trainIters(\n",
    "        index_array_pairs, encoder, attn_decoder, n_epochs, max_length, \n",
    "        print_every, plot_every = plot_every, \n",
    "        learning_rate = learning_rate, max_hours = max_hours,\n",
    "        clip = clip)\n",
    "    \n",
    "    # return trained models and info to plot the losses\n",
    "    return encoder, attn_decoder, plot_losses, plot_every\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data files preprocessed ...\n",
      "\n",
      "28 inputs constructed for training ...\n",
      "\n",
      "0m 8s (- 3m 16s) (56 4%) 4.4199\n",
      "0m 20s (- 3m 51s) (112 8%) 4.1312\n",
      "0m 28s (- 3m 30s) (168 12%) 3.9607\n",
      "0m 38s (- 3m 23s) (224 16%) 3.7780\n",
      "0m 47s (- 3m 9s) (280 20%) 3.5683\n",
      "0m 54s (- 2m 53s) (336 24%) 3.3428\n",
      "1m 2s (- 2m 40s) (392 28%) 3.1180\n",
      "1m 9s (- 2m 28s) (448 32%) 2.9107\n",
      "1m 17s (- 2m 17s) (504 36%) 2.7221\n",
      "1m 26s (- 2m 9s) (560 40%) 2.5532\n",
      "1m 34s (- 1m 59s) (616 44%) 2.3895\n",
      "1m 41s (- 1m 50s) (672 48%) 2.2542\n"
     ]
    }
   ],
   "source": [
    "#### TOY DATA\n",
    "\n",
    "hidden_size = 256 \n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_epochs = 50\n",
    "max_hours = 9\n",
    "clip = 10\n",
    "\n",
    "MAX_LENGTH = 24\n",
    "(encoder, attn_decoder, slang, tlang, plot_losses, max_bpe_length) = pipeline.run(\n",
    "    fp.spath_toy, fp.tpath_toy, \n",
    "    fp.spath_toy, fp.tpath_toy, \n",
    "    train_model, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = False, \n",
    "    use_bpe = True, num_operations = 80, vocab_threshold = 1,\n",
    "    padding = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TUTORIAL DATA - no BPE\n",
    "\n",
    "hidden_size = 256 \n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_iters = 75000\n",
    "max_hours = 2\n",
    "\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "(encoder, attn_decoder, slang, tlang, plot_losses) = pipeline.run(\n",
    "    fp.spath_tutorial, fp.tpath_tutorial, \n",
    "    fp.spath_tutorial, fp.tpath_tutorial, \n",
    "    train_model, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = False, \n",
    "    use_bpe = False, num_operations = 200, vocab_threshold = 2,\n",
    "    padding = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TUTORIAL DATA\n",
    "\n",
    "hidden_size = 256 \n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_iters = 75000\n",
    "max_hours = 9\n",
    "\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "(encoder, attn_decoder, slang, tlang, plot_losses) = pipeline.run(\n",
    "    fp.spath_tutorial, fp.tpath_tutorial, \n",
    "    fp.spath_tutorial, fp.tpath_tutorial, \n",
    "    train_model, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = False, \n",
    "    use_bpe = True, num_operations = 200, vocab_threshold = 2,\n",
    "    padding = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TRAIN and TEST DATA using BPE\n",
    "\n",
    "hidden_size = 256 \n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_iters = 300000\n",
    "max_hours = 10\n",
    "clip = 8\n",
    "use_bpe = True\n",
    "replace_unknown_words = True\n",
    "padding = False\n",
    "MAX_LENGTH = 17\n",
    "\n",
    "(encoder, attn_decoder, slang, tlang, plot_losses, max_bpe_length) = pipeline.run(\n",
    "    fp.spath_train, fp.tpath_train, \n",
    "    fp.spath_val, fp.tpath_val, \n",
    "    train_model, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = True, \n",
    "    use_bpe = True, num_operations = 400, vocab_threshold = 5, \n",
    "    padding = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TRAIN and TEST DATA no BPE\n",
    "\n",
    "hidden_size = 256 \n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_iters = 80000\n",
    "max_hours = 8\n",
    "\n",
    "MAX_LENGTH = 25\n",
    "(encoder, attn_decoder, slang, tlang, plot_losses) = pipeline.run(\n",
    "    fp.spath_train, fp.tpath_train, \n",
    "    fp.spath_test, fp.tpath_test, \n",
    "    train_model, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = True, \n",
    "    use_bpe = False, \n",
    "    padding = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import filepaths as fp\n",
    "import data_preparation as dp\n",
    "\n",
    "from plots import showLosses, showAttention\n",
    "from data_processing import preprocess, postprocess\n",
    "\n",
    "def sanity_check(spath_train, tpath_train, \n",
    "        spath_test, tpath_test, \n",
    "        fn_train, fn_predict_all,\n",
    "        max_sentence_length = 50, \n",
    "        replace_unknown_words = True, \n",
    "        use_bpe = True, num_operations = 400, vocab_threshold = 5,\n",
    "        padding = True):\n",
    "\n",
    "    # data preprocessing\n",
    "    (spath_train_pp, tpath_train_pp, spath_test_pp, tpath_test_pp) = preprocess(\n",
    "        spath_train, tpath_train, spath_test, tpath_test, \n",
    "        max_sentence_length,\n",
    "        replace_unknown_words, \n",
    "        use_bpe, num_operations, vocab_threshold)\n",
    "\n",
    "    print (f'Data files preprocessed ...')\n",
    "    print ()\n",
    "    \n",
    "    # data structures for training\n",
    "    (slang, tlang, index_array_pairs, s_index_arrays_test, max_bpe_length) = dp.prepare_data(\n",
    "        spath_train_pp, tpath_train_pp, spath_test_pp, padding)\n",
    "        \n",
    "    return slang, tlang, index_array_pairs, max_bpe_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size = 256 \n",
    "dropout_p = 0.1\n",
    "learning_rate = 0.01\n",
    "n_iters = 300000\n",
    "max_hours = 10\n",
    "clip = 8\n",
    "use_bpe = True\n",
    "replace_unknown_words = True\n",
    "padding = False\n",
    "\n",
    "MAX_LENGTH = 17\n",
    "slang, tlang, index_array_pairs, max_bpe_length = sanity_check(\n",
    "    fp.spath_train, fp.tpath_train, \n",
    "    fp.spath_test, fp.tpath_test, \n",
    "    sanity_ckeck, predict_all, \n",
    "    max_sentence_length = MAX_LENGTH, \n",
    "    replace_unknown_words = replace_unknown_words, \n",
    "    use_bpe = use_bpe, \n",
    "    padding = padding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [0,1, 10000, 20000, 28317, 28318]:\n",
    "    print(dp.sentenceFromIndexes(slang, index_array_pairs[i][0]))\n",
    "    print(dp.sentenceFromIndexes(tlang, index_array_pairs[i][1]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderRNN(\n",
       "  (embedding): Embedding(114, 256)\n",
       "  (gru): GRU(256, 256)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#encoder, attn_decoder, slang, tlang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_preparation as dp\n",
    "\n",
    "s_sentence = 'une a@@ b@@ e@@ il@@ le pl@@ an@@ ant a@@ u@@ -@@ de@@ s@@ su@@ s de f@@ l@@ e@@ ur@@ s v@@ i@@ ol@@ e@@ t@@ t@@ es et or@@ an@@ g@@ es .'\n",
    "s_words = s_sentence.split(' ')\n",
    "s_indices = dp.indexesFromSentence(\n",
    "    slang, \n",
    "    s_sentence\n",
    ")\n",
    "\n",
    "t, a = predict(\n",
    "        encoder, attn_decoder, s_indices, max_bpe_length)\n",
    "\n",
    "t_words = dp.wordsFromIndexes(tlang,t)\n",
    "A = a.numpy() # 19 output * 60 input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'une abeille planant au-dessus de fleurs violettes et oranges .'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_sentence.replace('@@ ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "merge_indices = [i for i, w in enumerate(s_words) if w.endswith('@@')]\n",
    "resulting_columns = []\n",
    "merge_column = np.array([])\n",
    "resulting_words = []\n",
    "merge_word = ''\n",
    "for i, column in enumerate(A.T):\n",
    "    if not merge_column.any():\n",
    "        merge_column = column\n",
    "        merge_word = s_words[i] if i < len(s_words) else ''\n",
    "    else:\n",
    "        merge_column = (merge_column + column)\n",
    "        merge_word += s_words[i]\n",
    "    if i not in merge_indices:\n",
    "        resulting_words.append(merge_word)\n",
    "        resulting_columns.append(merge_column)\n",
    "        merge_column = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['une',\n",
       " 'a@@b@@e@@il@@le',\n",
       " 'pl@@an@@ant',\n",
       " 'a@@u@@-@@de@@s@@su@@s',\n",
       " 'de',\n",
       " 'f@@l@@e@@ur@@s',\n",
       " 'v@@i@@ol@@e@@t@@t@@es',\n",
       " 'et',\n",
       " 'or@@an@@g@@es',\n",
       " '.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulting_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 35)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.column_stack(resulting_columns)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merge_indices = [i for i, w in enumerate(t_words) if w.endswith('@@')]\n",
    "resulting_rows = []\n",
    "merge_row = np.array([])\n",
    "resulting_words = []\n",
    "merge_word = ''\n",
    "for i, row in enumerate(X):\n",
    "    if not merge_row.any():\n",
    "        merge_row = row\n",
    "        merge_word = t_words[i] if i < len(t_words) else ''\n",
    "    else:\n",
    "        merge_row = (merge_row + row)/2.\n",
    "        merge_word += t_words[i]\n",
    "    if i not in merge_indices:\n",
    "        resulting_words.append(merge_word)\n",
    "        resulting_rows.append(merge_row)\n",
    "        merge_row = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resulting_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'wat@@er@@f@@all',\n",
       " 'in',\n",
       " 'a',\n",
       " 'for@@e@@s@@t',\n",
       " 'with',\n",
       " 'm@@an@@y',\n",
       " 't@@re@@es',\n",
       " 'EOS']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulting_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999986961484"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(resulting_rows[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resulting_rows = []\n",
    "merge_row = np.array([])\n",
    "for i, row in enumerate(A):\n",
    "    if i > len(merge_indices):\n",
    "        break    \n",
    "    if not merge_column.any():\n",
    "        merge_column = column\n",
    "    else:\n",
    "        merge_column = (merge_column + column)/2.\n",
    "    if i not in merge_indices:\n",
    "        resulting_columns.append(merge_column)\n",
    "        merge_column = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mj = np.column_stack(resulting_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 35)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000128056854"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mj[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_bpe_s(s_words, A):\n",
    "    merge_indices = [i for i, w in enumerate(s_words) if w.endswith('@@')]\n",
    "    resulting_columns = []\n",
    "    merge_column = np.array([])\n",
    "    resulting_words = []\n",
    "    merge_word = ''\n",
    "    for i, column in enumerate(A.T):\n",
    "        if not merge_column.any():\n",
    "            merge_column = column\n",
    "            merge_word = s_words[i] if i < len(s_words) else ''\n",
    "        else:\n",
    "            merge_column = (merge_column + column)\n",
    "            merge_word += s_words[i]\n",
    "        if i not in merge_indices:\n",
    "            resulting_words.append(merge_word)\n",
    "            resulting_columns.append(merge_column)\n",
    "            merge_column = np.array([])\n",
    "    return resulting_words, np.column_stack(resulting_columns)\n",
    "        \n",
    "def merge_bpe_t(t_words, X):\n",
    "    merge_indices = [i for i, w in enumerate(t_words) if w.endswith('@@')]\n",
    "    resulting_rows = []\n",
    "    merge_row = np.array([])\n",
    "    resulting_words = []\n",
    "    merge_word = ''\n",
    "    for i, row in enumerate(X):\n",
    "        if not merge_row.any():\n",
    "            merge_row = row\n",
    "            merge_word = t_words[i] if i < len(t_words) else ''\n",
    "        else:\n",
    "            merge_row = (merge_row + row)/2.\n",
    "            merge_word += t_words[i]\n",
    "        if i not in merge_indices:\n",
    "            resulting_words.append(merge_word)\n",
    "            resulting_rows.append(merge_row)\n",
    "            merge_row = np.array([])\n",
    "    return resulting_words, np.row_stack(resulting_rows)\n",
    "        \n",
    "def merge_bpe(s_words, output_w, a):\n",
    "    s_words_merged, X = merge_bpe_s(s_words, A)\n",
    "    t_words_merged, attentions = merge_bpe_t(t_words, X)\n",
    "    return (s_words_merged, t_words_merged, attentions)\n",
    "\n",
    "q,r,s = merge_bpe(s_words, t_words, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000053900294"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object chain at 0x7fb5ecfcd0a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from itertools import chain\n",
    "chain(encoder.parameters(), attn_decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xchain(*iterables):\n",
    "    # chain('ABC', 'DEF') --> A B C D E F\n",
    "    for it in iterables:\n",
    "        for element in it:\n",
    "            yield element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fb5ecfcd728>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.ceil(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
